{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Rohit Lal\"\n",
    "__copyright__ = \"Copyright (C) 2020 Rohit Lal\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np,os\n",
    "\n",
    "## The classes imported below are used for dataloader, transformation and model\n",
    "\n",
    "from DAE_dataset_helper import OrigamiDatasetGenerate,ValidationGenerate\n",
    "from DAE_dataset_helper import ToTensor,Resize, Normalize\n",
    "from DAE_dataset_helper import ToTensorValidate,NormalizeValidate,ResizeValidate\n",
    "from DAE_model import AugmentedAutoencoder # contains various models to be tested on \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "test_batch_size = 4\n",
    "split_percent = 0.8\n",
    "\n",
    "origami_dataset_dir = \"/home/rohit/projects/autoencoder/MarowDataset\"\n",
    "inp='Input'\n",
    "out='Output'\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "trns = transforms.Compose([Resize((128,128)), Normalize(),ToTensor()])\n",
    "origami = OrigamiDatasetGenerate(root_dir=origami_dataset_dir,inp=inp, out=out, transform=trns)\n",
    "\n",
    "train_size = int(split_percent * len(origami))\n",
    "test_size = abs(len(origami) - train_size)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(origami, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size,\n",
    "                            shuffle=True,**kwargs)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size,\n",
    "                            shuffle=True,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your Dataset \n",
    "## Remeber the below cell consumes precious GPU if used in notebook. \n",
    "Its better not run this part when u r planning to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(test_loader)\n",
    "sample = iterator.next()\n",
    "augmented,original = sample['augmented'],sample['original']\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "images_show = 8\n",
    "print('Input to network')\n",
    "imshow(torchvision.utils.make_grid(augmented[:images_show,:], nrow=4, padding=2, pad_value=1))\n",
    "print('Output of network (To be verified with)')\n",
    "imshow(torchvision.utils.make_grid(original[:images_show,:], nrow=4, padding=2, pad_value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions of training and testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch,log_interval=10):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        data, target = sample['augmented'],sample['original']\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch,loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for c, sample in enumerate(test_loader):\n",
    "            data, target = sample['augmented'],sample['original']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.binary_cross_entropy(output,target) # sum up batch loss\n",
    "    test_loss /= max(1,c)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "save_model = True\n",
    "saved_pth = 'AE.pt'\n",
    "\n",
    "model = AugmentedAutoencoder().to(device)\n",
    "\n",
    "if os.path.exists(saved_pth):\n",
    "    model.load_state_dict(torch.load(saved_pth))\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=15)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1), unit='epochs'):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "    if save_model and epoch%10 ==0:\n",
    "        torch.save(model.state_dict(), saved_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate with your own Image\n",
    "Just change the folder in variable `origami_test_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, device, test_loader,viewer=True):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        validator = iter(test_loader)\n",
    "        sample = next(validator)\n",
    "        \n",
    "        sample = sample.to(device)\n",
    "        output = model(sample)\n",
    "        encodings = model.encoder_op(sample)\n",
    "        \n",
    "    if viewer:\n",
    "        images_show = 8\n",
    "        \n",
    "        print('Reconstructed')\n",
    "        op = output[:images_show,:].cpu()\n",
    "        imshow(torchvision.utils.make_grid(op, nrow=4, padding=2, pad_value=1))\n",
    "                \n",
    "        print('Input to Netowrk')\n",
    "        imshow(torchvision.utils.make_grid(sample[:images_show,:].cpu(), nrow=4, padding=2, pad_value=1))  \n",
    "        \n",
    "    return sample, output, encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origami_test_dir = \"MarowDataset/Test\"\n",
    "val_batch_size = 12\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "\n",
    "trns = transforms.Compose([ResizeValidate((128,128)), NormalizeValidate(),ToTensorValidate() ])\n",
    "validator = ValidationGenerate(root_dir=origami_test_dir, transform=trns)\n",
    "val_loader = DataLoader(validator, batch_size=val_batch_size,\n",
    "                            shuffle=True,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, output, encodings = cross_validation(model, device, val_loader,viewer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}